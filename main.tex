\documentclass[runningheads]{llncs}

\usepackage{graphicx}
\usepackage{array}
\usepackage{booktabs}
\usepackage{float}

\begin{document}
\title{Automatic Evaluation of Generative Dialogue Systems: An Empirical Study}

\titlerunning{Automatic Evaluation of Generative Dialogue Systems}

\author{Cong Feng\inst{1} \and Wenge Rong\inst{1}}

\authorrunning{C. Feng et al.}

\institute{School of Computer Science and Engineering,
Beihang University, Beijing, China
\email{cgsdfc@126.com} \\
\email{w.rong@buaa.edu.cn}
}

\maketitle

\begin{abstract}
    It has been known that in the field of conversation response generation, the automatic metrics correlate poorly with human judgement.
    In this paper, we try to learn the correlation between the scores computed by different automatic metrics.
    By an empirical study we show that the distributions of the utterance-level scores vary but the correlation between them highlights some regular patterns.
    Following these patterns we derive clusterings of these distributions,
\keywords{Automatic Metrics, Response Generation, Chatbot}
\end{abstract}


\section{Introduction}

\section{Related Work}
Related work on metrics.

\section{Experiment Setup}
Explain the metrics, models and datasets we used.

\subsection{Metrics}
Introduce metrics, one per paragraph.
\paragraph{BLEU.}
\paragraph{METEOR.}
\paragraph{ROUGE.}

\paragraph{Greedy Matching.}
\paragraph{Embedding Average.}
\paragraph{Vector Extrema.}

\paragraph{Distinct-N.}
\paragraph{Utterance length.}

\subsection{Models}
Introduce models, one per paragraph.
\paragraph{LSTM language model.}
\paragraph{HRED.}
\paragraph{VHRED.}

\subsection{Datasets}
Introduce datasets, one per paragraph.
\paragraph{Ubuntu Dialogue Corpus}
\paragraph{OpenSubtitles}
\paragraph{LSDSCC}


\section{Experimental Study}
\paragraph{Statistical Analysis.}
Display the clustering of metrics through multiple perspectives,
such as the similarity of their distribution plots, tables of Pearson and Spearman Correlation
and the visualization outcomes of a certain clustering algorithm.

\paragraph{Qualitative Analysis.}
Display and analyze some examples where different metrics disagree greatly.
For example, a response with no n-gram overlap will get zero BLEU but if it is semantically
relevant to the message or reference, embedding-based metric will give it a high score.

\section{Discussion}
Conclusions from the experiment.
Advice on using metrics.

\subsection*{Acknowledgements.}

\bibliographystyle{splncs04}
\bibliography{data/all}

\end{document}
